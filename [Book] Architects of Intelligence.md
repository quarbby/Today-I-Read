# Architects of Intelligence by Martin Ford
**Link:** https://www.amazon.com/Architects-Intelligence-truth-people-building-ebook/dp/B07H8L8T2J

### YOSHUA BENGIO

“YOSHUA BENGIO: I’ve always valued academia and the freedom to work for the common good or the things that I believe would “have more impact. I also value working with students both psychologically and in terms of the efficiency and productivity of my research. If I went into the industry, I would be leaving a lot of that behind.”

Avoid killer robots, military and weaponisation
“Let me go back to this question about a human in the loop because I think this is really important. People need to understand that current AI—and the AI that we can foresee in the reasonable future—does not, and will not, have a moral sense or moral understanding of what is right and what is wrong. I know there are differences across cultures, but these moral questions are important in people’s lives.”

“It’s not just about precision, it’s about understanding the human context,”

“We have to consider what the right social mechanism is that will make sure that AI is used for good.”

“don’t trust companies to do it by themselves because their main focus is on maximizing profits. Of course, they’re also trying to remain popular among their users or customers, but they’re not completely transparent about what they do. It’s not always clear that those objectives that they’re implementing correspond to the well-being of the population in general.”

“How do we develop AI in a way that’s both economically positive and keeps the trust of the people?”

### Stuart j Russell
“An entity is intelligent to the extent that it does the right thing, meaning that its actions are expected to achieve its objectives.”

“We are just beginning now to get some theoretical understanding of when and why the deep learning hypothesis is correct, but to a large extent, it’s still a kind of magic, because it re”

“I think that many of the conceptual building blocks needed for AGI or human-level intelligence are already here. But there are some missing pieces. One of them is a clear approach to how natural language can be understood to produce knowledge structures upon which reasoning processes can operate

### NICK BOSTROM

“I wouldn’t say species membership is the main criterion here that we use to posit consciousness, there are a lot of human beings that are not conscious. Maybe they are in a coma, or they are fetuses, or they could be brain dead, or under deep anesthesia. Most people also think you can be a non-human being, for instance, certain animals, let us “say, have various degrees and forms of conscious experience. So, we are able to project it outside our own species, but I think it is true that it will be a challenge for human empathy to extend the requisite level of moral consideration to digital minds, should such come to exist.”

### Yann Lecun 

“I don’t think we’re going to see an AI winter in the way we saw before because there is a big industry around it and there are real applications that are bringing real revenue to these companies.

There’s still a huge amount of investment, with the hope that, for example, self-driving cars are going to be working in the next five years and that medical imaging is going to be radically revolutionized. Those are probably going to be the most visible effects over the next few years, medicine and health care, transportation, and information access.”

### Fei Fei Li

“If you look at the way nature designed our brain, half of the human brain is involved in human intelligence, and that human intelligence is intimately related to a motor system, to decision-making, to emotion, to intention, and to language. The human brain does not just happen to recognize 
“isolated objects; these functions are an integral part of what deeply defines human intelligence.”

“AGI would be the kind of intelligence that is contextualized, situationally aware, nuanced, multifaceted and multidimensional”

### Dennis hassabis 

“As a neuroscientist, I think that the journey we’re on of building neuroscience-inspired AI is one of the best ways to address some of the complex questions we have about the brain. If we build an AI system that’s based on neuroscience, we can then compare it to the human brain and maybe start gleaning some information about its unique characteristics. We could start shedding light on some of the profound mysteries of the mind like the nature of consciousness, creativity, and dreaming. I think that comparing the brain to an algorithmic construct could be a way to understand that.”

### ANDREW NG

“There are hundreds of different things that deep learning doesn’t do, and causality is one of them. There are other things, such as not doing explainability well enough; we need to sort out how to defend against adversarial attacks; we need to get a lot better at learning from small datasets rather than big datasets; we need to get much better at transfer or multitask learning; we need to figure out how to use unlabeled data better.”

### RANA EL KALIOUBY

“Because the data is coming from people, so inevitably it incorporates their biases. You’re saying that it isn’t the algorithms that are biased, it’s the data.”

### RAY KURZWEIL

“The field of AI had already bifurcated into two warring camps: the symbolic school and the connectionist school. The symbolic school was definitely in the ascendancy with Marvin Minsky regarded as its leader. The connectionists were the “upstarts, and one such person was Frank Rosenblatt at Cornell University, who had the first popularized neural net called the perceptron.”

“At Google we’re making progress in natural language, and language was the first invention of the neocortex. Language is hierarchical; we can share the hierarchical ideas we have in our neocortex with each other using the hierarchy of language. I”

“A) they are thinking linearly, and B) they are subject to what I call the engineer’s pessimism—that is being so focused on one problem and feeling that it’s really hard because they haven’t solved it yet, and extrapolating that they alone are going to solve the problem at the pace they’re working on. It’s a whole different discipline to consider the pace of progress in a field and how ideas interact with each other and study that as a phenomenon. Some people are just not able to grasp the exponential nature of progress, particularly when it comes to information technology.”

### DANIELA RUS

“I’m very bullish about the future progress in grasping and manipulation. I think that soft hands, and in general, soft robots are going to be a very critical aspect of advancement in dexterity, just like the laser scanner was a critical aspect of advancing the navigation capabilities of robots.”

“he final thing I want to say about the future of work is that our attitude toward learning will also have to change. Today, we operate with a sequential model of learning and working. What I mean by this is that most people spend some chunk of their lives studying and at some point, they say, “OK, we’re done studying, now we’re going to “start working.” With technology accelerating and bringing in new types of capabilities, though, I think it’s very important to reconsider the sequential approach to learning. We should consider a more parallel approach to learning and working, where we will be open to acquiring new skills and applying those skills as a lifelong learning process.”

“Her research addresses some of the gaps between where robots are today and the promise of pervasive robots: increasing the ability of machines to reason, learn, and adapt to complex tasks in human-centered environments, developing intuitive interfaces between robots and people, and creating the tools for designing and fabricating new robots quickly and efficiently. The applications of this work are broad and include transportation, manufacturing, agriculture, construction, monitoring the environment, underwater exploration, smart cities, medicine, and in-home tasks such as cooking.”

### JAMES MANYIK

“It may not be the biases that any human being has in developing the algorithms, but the way in which we’ve collected the data that the algorithms are trained on that introduces bias.”
“Another issue is explainability. Here, explainability is a term used to discuss the problem that with neural networks: we don’t always 
“know which feature or which dataset influenced the AI decision or prediction, one way or the other. This can make it very hard to explain an AI’s decision, to understand why it might be reaching a wrong decision.”

### BARBARA GROSZ

"I mentioned one hurdle, which is getting the wide range of data that would be needed and getting that data ethically because you’re essentially being Big Brother and watching a lot of behavior and from that, taking a lot of data from a lot of people. I think that may be one of the biggest issues and biggest hurdles.

The second hurdle is that every AI system that exists today is an AI system with specialized abilities. Robots that can clean your house or systems that can answer questions about travel, or restaurants. To go from that kind of individualized intelligence to general intelligence that flexibly moves from one domain to another domain, and takes analogs from one domain to another, and can think not just “about the present but also the future, those are really hard questions.”

### DAPHNE KOLLER

This is a subtle answer that has several aspects. Probabilistic models lie on a continuum between those that try to encode the domain structure in an interpretable way—a way that makes sense to humans—and those that just try to capture the statistical properties of the data. The deep learning models intersect with probabilistic models—some can be viewed as encoding a distribution. Most of them have elected to focus on maximizing the predictive accuracy of the model, often at the expense of interpretability. Interpretability and the ability to incorporate structure in the domain has a lot of advantages in cases where you really need to understand what the model does,”

### DAVID FERRICHI

“Today’s systems do more text matching and looking at the statistical occurrences of words and phrases, as opposed to developing a layered and logical representation of the complex logic that is really behind the language.”

“Deep learning and neural networks are powerful because they can find nonlinear, very complex functions in large volumes of data.”

“Our goal is to produce an intelligence that is anchored in logic, language and reason because we want to produce a compatible human intelligence. In other words, we want to pro”


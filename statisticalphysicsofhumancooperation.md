Authors: Matjaz Perc, Jillian J. Jordan, David G. Rand, Zhen Wang, Stefano Boccaletti, Attila Szolnoki
Link: https://arxiv.org/pdf/1705.07161.pdf

This paper reviews experimental and theoretical human experiments that advances the understanding of human group interactions, elaborating on the variations of the Public Goods Game which depict human behaviour.

## Public Goods Game

### Overview

The Public Goods Game is the most common experimental game in examining cooperation between humans. In the game, each member of the group starts with an endowement and decides how much to contribute to the public good. Contributions are then multiplied by the experimenter, then divided equally among all the players. Contributing to the public good is a positive sum, but strictly costly to the individual; the Nash Equilibrium is of zero contributions by all, but that is rarely seen in experiments. All players are better off if each player makes a full contribution to the public good. 

Punishment comes in reduction of payoffs, retaliation or norm enforcement. Experimental results show punishment via payoffs are generally systematically targeted at low contributors, however some societies result in anti-social punishment which targets punishment at contributors. To measure retaliation, or second-party punishment, a game called the Ultimatum Game is used. In this game, the payoff-maximizing action is for the responder to accept any non-zero offer. In almost all societies, there is some rejection of offers, but rejection rates decline as offer size increases. Norm enforcement, or third-party punishment, may be motivated by reputational benefits, which are more likely to occur when behaviour is observable. 

Examples of Public Goods Games include predator inspection behaviour, alarm calls and group defense. In human societies, policies such as insurance and public transportations reflect the use of contribution to a public good. 

### Assumptions

The aggregate behaviour is a valid model of how individuals are behaving. 

Players have some form of social preferences, for fairness, equity and efficiency. When other members contribute less than an individual, he will be concerned with disadvantageous inequality. 

Humans can be divided into fair-minded co-operators that act for the good of the group and free riders that exploit the altruism of others. Free riders are generally considered in the game as players who make zero-sum contributions.

The effect of the public good is a linear function of the number of contributions. While this simplifies the observation space, public goods games can come to polynomial equilibria as well. 

The null model is built upon uniform random selection of players in a well-mixed population, but interactions between humans are seldom random. The paper tries to account for this by constructing different types of lattices to represent the imitation networks of the players. 

### Limitations

Gameplay differs across different cultures. Most of the experiments have been conducted in western, educated, industrialized, rich and democratic societies, which reflected the average contribution at 50%. One study of other complexed and developed societies across the world have shown variations – 70% contribution in Copenhagen to 40% in Athens. 

Human subjects do not always follow rational reasoning. 

Human subjects may get confused over time as they do not understand the difference in actual and expected payout, resulting in a deviation of behaviour. This is known as cooperative decay. 


## Punishment 

### Overview

Punishment is retaliation or negative reciprocity, which entails paying a cost for somebody else to incur a cost. 

In peer punishment, individual players take it upon themselves to punish defectors. The null model can be upgraded to introduce a third competing strategy where co-operators punish defectors. A defector is punished when it is networked to a cooperator; defectors bear the largest cost when surrounded solely by co-operators. 

In pool punishment, those willing to punish invest into a common pool of resources to punish a defector. This is similar to institutional punishments like police or the justice, where cost of punishment is born by taxes paid by the public. Pool punishment requires precursive allocation of resources to the punishment pool, irrespective of strategies. 

Self-organised punishment accounts for players changing their strategies in response to the success of cooperation through an additional parameter keeping score of its punishing activity. The presence of defectors alone do not trigger an increase in punishing activity; the spread of defectors do. Conversely, if defectors fail to spread, punishers reduce their cost by one. 

### Assumptions

Players agree to the precursive percentage of resource allocation for punishment. 

Pool punishers agree to a lower income than cooperators which results because of their permanent contributions to the punishment pool.

Peer and pool punishment assume that once the cost of punishment is set, it does not change over time. 

### Limitations

The model does not consider counter-punishments by defectors. Nikiforakis (2007) describes a social dilemma of counter-punishment opportunities, which may have an effect on individual earnings. The weakening of the punishment threat makes free riding profitable for some individuals. Nikiforakis’ studied utility form retaliation where players impose suffering on others who make them suffer, usually by imposing a larger severity of counter-punishment. He also indicated some punishments may be due to spiteful behaviour, where players take action that hurt others more than they hurt the player. 

The model does not consider incomplete punishment networks, where only certain players can punish others, and some players cannot be punished. This mimics the real-life where some humans have authority over others. Leibbrandt et. al (2015) experimented with such networks, concluding that the greater the number of people who can be punished, the greater the contributions to the public good. High contributions are only sustained in complete and untouchable networks: networks where all players can be punished and networks where certain players have authority over others.

## Reward

### Overview

Rewarding is a sign of positive reciprocity, paying a cost for someone else to incur a benefit. 

Peer Reward can be implemented as an extension of the null model, rewarding cooperators, though each rewarding cooperator bears an additional cost. 

Pool Reward is seldom found in human societies, except may criminal organisations that reward members if their crime is done right. 

Self-Organised Rewarding allows for players to adapt their reward efforts in dependence on their success in cooperation. 

### Assumptions

The paper considers a strategy-neutral pool of players. 

### Limitations

The model considers first-order rewarding strategies, in which the players directly receive the reward at each turn. Other forms of rewards commonly found in human societies include delayed gratification and accumulation of rewards. 

## Tolerance

### Overview

Tolerance is an endurance of a trying circumstance with a fair and objective attitude. There are as many levels of tolerance as there are possible defectors in a group. The higher the level of tolerances a player has, the more defectors the player can tolerate. Defectors are players with low contributions. Tolerance towards defectors can not only save cooperation if the multiplication factor is low, but result in a surprisingly high average payoff in the population. 

New strategies of play sometimes emerge among players when the tolerance threshold increases, allowing Tolerant Players to tolerate more defectors in the group. Tolerance can also create cycles of dominance between Defectors, Loners and Tolerants. Sometimes, a stable coexistence of four player-type phases can be observed, with Defectors, Loners, Cooperators and Tolerants. 

Plotting out the phase diagrams highlights there is an optimal intermediate tolerance level for the best condition for tolerant players to survive, though they always bear this cost on top of the cost of cooperation. In all phases, an intermediate tolerance level is optimal; too high or too low tolerance results in phase evolutions. 

The paper also modelled phase diagrams of diverse tolerance levels in a population, to determine whether evolutionary advantages may stem from multiple tolerant strategies. 

### Assumptions

Tolerance levels can be discretized. Other papers (Ghosh & Halpern, 2017) explore the game with a distribution profile over possible tolerances for each player. 

Players are chosen from the same pool, and factors that may affect tolerance levels such as culture, background and social-economic statuses do not affect tolerance levels of a player. 

There is a reasonable number of players of each type to give significant weights to each factor. 

### Limitations

Humans are fair and objective, despite the changes in circumstances. However, humans can be irrational and rely on emotions rather than logic. 

The paper only explored a snapshot of carefully engineered combinations of tolerance levels, to understand phase changes in combinations of tolerances in a population. In these combinations, loners first die out, followed by pure co-operators, demonstrating the importance of diversity and tolerance for human cooperation.  

The paper did not explore conditions when players adopt different tolerance levels to different conditions. 

## Institutionalized Strategies

### Overview

Institutionalized Strategies aim at promoting pool punishment and rewards. 

Spatiotemporal complexity due to pool punishment occurs most frequently in law and justice in human societies. Much research concludes that pool-punishers prevail only if second-order freeriders are punished as well. Cooperators who refuse the bear the cost of punishment are unable to survive. 

Institutionalized rewarding is typically non-existent in human societies, as it is difficult to find the optimal distribution of institutional incentives. If group interactions are weak, the level of cooperation can be maximised by equal-reward principle; however, most multiplication factor rewards high-degree nodes more than low-degree nodes. 

### Assumptions

Sustainability in pool punishment relies on the sustained numbers of pool-punishers. 

### Limitations

Empirical research on institutionalized rewarding is limited. 

Absolute and degree-normalized payoffs need to be considered for heterogeneous interaction networks. 

## Evolutionary 

### Overview

The dynamics of cooperation evolves over time. One evolution results in enhanced network reciprocity due to adaptive punishment, where localised and temporarily active punishes can emerge in response to Defector (D) -> Cooperator (C) invasions, establishing regularity of the D -> C interface. 

Another evolutionary method of punishment is probabilistic sharing of costly punishment, distributing the duty. 

### Assumptions

The paper assumes evolution takes place only at phase transitions. Evolution can take place within phases, where players can adopt different strategies in contribution and punishment, without breaking the threshold to cross the boundaries. 

Phase boundaries of thresholds are arbitrarily determined. These boundaries may differ over different human societies and age groups. 

### Limitations

The paper studied adaptive peer rewarding only on square lattices. 

The paper did not elaborate fully the model used for probabilistic sharing of costly punishment.

Antisocial strategies have not been systematically studied, neither have antisocial pool rewarding and prosocial pool rewarding. 

## Monte Carlo Methods for Experiments

### Overview

In order to conduct simulations on the Public Goods Game, the paper used Monte Carlo methods to study a structured population. 

Random sequential strategy updating is used to study the Null/Punishment/Reward/Tolerance strategies, as it enables comparision with generalised mean field approximation. This strategy update allows for determination of phase transitions. Each player changes its strategy once on average, or in accordance to the Fermi-Dirac distribution in an attempt to imitate the strategy of one of its neighbour at random. 

Random initial conditions start off the simulation to make certain each strategy occupies the same amount of space in a population, but that does not give equal chances of survival to all strategies. This concept is used as the authors do not know the initial configuration of strategies that will yield a stable subsystem solution, and thus adopted a random initial stage with a large system size to hope for convergence of strategies. 

Phase Transitions are used to model the changes in the players’ strategies. Continuous phase transitions in physics are characterised by critical exponents. In human cooperation, due to spatiotemporal dynamics of competing strategies, critical exponents, or situational factors, play the most prominent role. Discontinuous phase transitions can be observed through cyclic dominance phases, which could represent indirect territorial competition, or spontaneous emergence of cyclic dominance.

### Assumptions/ Limitations

Initial conditions of players are random. In human societies, some players have an advantage over others due to their socio-economic background. 

At the initial stage, all competing strategies are distributed uniformly at random. In human societies, players may slant towards a certain strategy due to cultural norms. 

A player imitates the strategy at one of its neighbouring players by random in accordance to the Fermi-Dirac distribution. In this distribution, it is assumed that the players in the system have negligible mutual interactions. It assumes a multi-player system (the game) cane be described in terms of single-particle states (each player), by assuming that the differences between each player are indistinguishable. This distribution assumes that the minmax rational approximation, or equilibrium will be reached; it is the Maxwell-Boltzmann distribution.

The simulation setup assumes that the randomised initial conditions will always result in a convergence of strategies for a stable subsystem. In human societies, circumstances such as a rebellion might arise to cause the society to diverge. 

We assume the paper has performed sufficiently large enough Monte Carlo Simulations with large population sizes. Figure 10 wrote the system size used was 2400. The Central Limit Theorem states that a sufficiently large sample size from the same population results in the mean of the samples from the same population to be approximately the mean of the population; that is, if a sufficiently large population size is chosen in the sampling by Monte Carlo Simulations, one would get an evenly distributed result that does not incur biasness. 



